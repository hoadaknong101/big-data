# Docker Compose Configuration - Local Mode (Fixed)

## ğŸ¯ Giáº£i PhÃ¡p Nhanh

File nÃ y chá»©a cáº¥u hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c fix Ä‘á»ƒ cháº¡y Spark Processor á»Ÿ **Local Mode**, khÃ´ng cáº§n spark-master vÃ  spark-worker.

## ğŸ“ Thay Äá»•i

### Cáº¥u HÃ¬nh CÅ© (Cluster Mode - CÃ³ Lá»—i)
```yaml
spark-processor-user-events:
  command: >
    /opt/spark/bin/spark-submit 
      --master spark://spark-master:7077  # â† Cáº§n worker
      --driver-memory 1g 
      --executor-memory 1g 
      --executor-cores 1
```

### Cáº¥u HÃ¬nh Má»›i (Local Mode - Hoáº¡t Äá»™ng)
```yaml
spark-processor-user-events:
  command: >
    /opt/spark/bin/spark-submit 
      --master local[2]  # â† KhÃ´ng cáº§n worker
      --driver-memory 1g
```

---

## ğŸ”§ CÃ¡ch Ãp Dá»¥ng

### Option 1: Sá»­a Trá»±c Tiáº¿p docker-compose.yml

Má»Ÿ file `docker-compose.yml` vÃ  thay tháº¿ pháº§n `spark-processor-user-events`:

```yaml
  spark-processor-user-events:
    build: ./spark_processor
    container_name: spark-processor-user-events
    env_file: .env
    environment:
      - RUN_MODE=user_events
    networks:
      - app-network
    depends_on:
      kafka:
        condition: service_healthy
      postgres-db:
        condition: service_healthy
    restart: on-failure
    command: >
      /bin/bash -c "
      echo 'Starting User Events Processor (Local Mode)...';
      sleep 20;
      sed -i 's/\r$//' /app/processor.py;
      /opt/spark/bin/spark-submit --master local[2] --driver-memory 1g --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0,org.postgresql:postgresql:42.6.0 --conf spark.sql.streaming.checkpointLocation=/tmp/checkpoint/user-events /app/processor.py
      "
```

TÆ°Æ¡ng tá»± cho `spark-processor-ratings`:

```yaml
  spark-processor-ratings:
    build: ./spark_processor
    container_name: spark-processor-ratings
    env_file: .env
    environment:
      - RUN_MODE=ratings
    networks:
      - app-network
    depends_on:
      kafka:
        condition: service_healthy
      postgres-db:
        condition: service_healthy
    restart: on-failure
    command: >
      /bin/bash -c "
      echo 'Starting Ratings Processor (Local Mode)...';
      sleep 20;
      sed -i 's/\r$//' /app/processor.py;
      /opt/spark/bin/spark-submit --master local[2] --driver-memory 1g --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0,org.postgresql:postgresql:42.6.0 --conf spark.sql.streaming.checkpointLocation=/tmp/checkpoint/ratings /app/processor.py
      "
```

### Option 2: Copy Paste ToÃ n Bá»™

Thay tháº¿ toÃ n bá»™ section tá»« `# 9. Spark Processor` Ä‘áº¿n háº¿t báº±ng code dÆ°á»›i Ä‘Ã¢y:

```yaml
  # 9. Spark Processor - Ratings (Local Mode)
  spark-processor-ratings:
    build: ./spark_processor
    container_name: spark-processor-ratings
    env_file: .env
    environment:
      - RUN_MODE=ratings
    networks:
      - app-network
    depends_on:
      kafka:
        condition: service_healthy
      postgres-db:
        condition: service_healthy
    restart: on-failure
    command: >
      /bin/bash -c "
      echo 'Starting Ratings Processor (Local Mode)...';
      sleep 20;
      sed -i 's/\r$//' /app/processor.py;
      /opt/spark/bin/spark-submit --master local[2] --driver-memory 1g --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0,org.postgresql:postgresql:42.6.0 --conf spark.sql.streaming.checkpointLocation=/tmp/checkpoint/ratings /app/processor.py
      "

  # 10. Spark Processor - User Events (Local Mode)
  spark-processor-user-events:
    build: ./spark_processor
    container_name: spark-processor-user-events
    env_file: .env
    environment:
      - RUN_MODE=user_events
    networks:
      - app-network
    depends_on:
      kafka:
        condition: service_healthy
      postgres-db:
        condition: service_healthy
    restart: on-failure
    command: >
      /bin/bash -c "
      echo 'Starting User Events Processor (Local Mode)...';
      sleep 20;
      sed -i 's/\r$//' /app/processor.py;
      /opt/spark/bin/spark-submit --master local[2] --driver-memory 1g --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0,org.postgresql:postgresql:42.6.0 --conf spark.sql.streaming.checkpointLocation=/tmp/checkpoint/user-events /app/processor.py
      "
```

---

## ğŸš€ Restart Services

Sau khi sá»­a:

```powershell
# Stop vÃ  remove containers cÅ©
docker compose down spark-processor-ratings spark-processor-user-events

# Start láº¡i
docker compose up -d spark-processor-user-events

# Xem logs
docker compose logs -f spark-processor-user-events
```

---

## âœ… Káº¿t Quáº£ Mong Äá»£i

Logs sáº½ hiá»ƒn thá»‹:

```
Starting User Events Processor (Local Mode)...
============================================================
BÆ°á»›c 1: Khá»Ÿi táº¡o Spark Session cho User Events Processing
============================================================
âœ“ Spark Session Ä‘Ã£ Ä‘Æ°á»£c khá»Ÿi táº¡o thÃ nh cÃ´ng

============================================================
BÆ°á»›c 2: Káº¿t ná»‘i tá»›i Kafka vÃ  subscribe topic 'user-events'
============================================================
Kafka Broker: kafka:9092
Topic: user-events
âœ“ ÄÃ£ káº¿t ná»‘i thÃ nh cÃ´ng tá»›i Kafka topic 'user-events'
...
```

**KHÃ”NG cÃ²n** cáº£nh bÃ¡o:
```
WARN TaskSchedulerImpl: Initial job has not accepted any resources
```

---

## ğŸ“Š Lá»£i Ãch Local Mode

âœ… **KhÃ´ng cáº§n spark-master vÃ  spark-worker**
âœ… **Ãt RAM hÆ¡n** (chá»‰ cáº§n 1-2GB thay vÃ¬ 4GB+)
âœ… **Setup Ä‘Æ¡n giáº£n hÆ¡n**
âœ… **PhÃ¹ há»£p cho development/testing**

âŒ **KhÃ´ng scale Ä‘Æ°á»£c** (chá»‰ cháº¡y trÃªn 1 machine)
âŒ **Giá»›i háº¡n resources** (local[2] = 2 cores)

---

## ğŸ“ Giáº£i ThÃ­ch

- `--master local[2]`: Cháº¡y Spark á»Ÿ local mode vá»›i 2 threads
- `local[*]`: Sá»­ dá»¥ng táº¥t cáº£ cores available
- `local[1]`: Chá»‰ 1 thread (slow nhÆ°ng Ã­t RAM)

---

**Ãp dá»¥ng fix nÃ y vÃ  há»‡ thá»‘ng sáº½ hoáº¡t Ä‘á»™ng ngay!** ğŸ‰
