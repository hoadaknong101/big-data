import os
from pyspark.sql import SparkSession
from pyspark.sql.functions import from_json, col, lit, current_timestamp, when, unix_timestamp
from pyspark.sql.types import StructType, StructField, StringType, IntegerType, LongType, TimestampType

# --- Configs ---
KAFKA_BROKER = os.environ.get('KAFKA_BROKER')
KAFKA_TOPIC = os.environ.get('KAFKA_TOPIC')
DB_USER = os.environ.get('POSTGRES_USER')
DB_PASSWORD = os.environ.get('POSTGRES_PASSWORD')
DB_HOST = os.environ.get('POSTGRES_HOST')
DB_NAME = os.environ.get('POSTGRES_DB')
DB_URL = f"jdbc:postgresql://{DB_HOST}:5432/{DB_NAME}"
DB_TABLE = "ratings"

# --- HÃ m Subscribe User Events ---
def subscribe_user_events():
    """
    HÃ m nÃ y thá»±c hiá»‡n subscribe topic 'user-events' tá»« Kafka vÃ  lÆ°u táº¥t cáº£
    cÃ¡c message má»›i vÃ o cÆ¡ sá»Ÿ dá»¯ liá»‡u PostgreSQL theo thá»i gian thá»±c.
    
    HÃ m sáº½ cháº¡y liÃªn tá»¥c vÃ  Ä‘á»£i khi cÃ³ message má»›i tá»« topic user-events.
    """
    
    # BÆ°á»›c 1: Khá»Ÿi táº¡o Spark Session
    # SparkSession lÃ  Ä‘iá»ƒm vÃ o chÃ­nh Ä‘á»ƒ lÃ m viá»‡c vá»›i Spark
    # AppName giÃºp nháº­n diá»‡n á»©ng dá»¥ng trong Spark UI
    print("=" * 60)
    print("BÆ°á»›c 1: Khá»Ÿi táº¡o Spark Session cho User Events Processing")
    print("=" * 60)
    
    spark = SparkSession \
        .builder \
        .appName("UserEventsSubscriber") \
        .getOrCreate()
    
    # Giáº£m má»©c Ä‘á»™ log Ä‘á»ƒ dá»… theo dÃµi, chá»‰ hiá»ƒn thá»‹ WARNING trá»Ÿ lÃªn
    spark.sparkContext.setLogLevel("WARN")
    print("âœ“ Spark Session Ä‘Ã£ Ä‘Æ°á»£c khá»Ÿi táº¡o thÃ nh cÃ´ng\n")
    
    # BÆ°á»›c 2: Káº¿t ná»‘i vÃ  Ä‘á»c stream tá»« Kafka topic 'user-events'
    # readStream: Táº¡o má»™t DataFrame streaming (dá»¯ liá»‡u liÃªn tá»¥c)
    # format("kafka"): Chá»‰ Ä‘á»‹nh nguá»“n dá»¯ liá»‡u lÃ  Kafka
    print("=" * 60)
    print("BÆ°á»›c 2: Káº¿t ná»‘i tá»›i Kafka vÃ  subscribe topic 'user-events'")
    print("=" * 60)
    print(f"Kafka Broker: {KAFKA_BROKER}")
    print(f"Topic: user-events")
    
    kafka_stream_df = spark \
        .readStream \
        .format("kafka") \
        .option("kafka.bootstrap.servers", KAFKA_BROKER) \
        .option("subscribe", "user-events") \
        .option("startingOffsets", "latest") \
        .load()
    
    # startingOffsets="latest": Chá»‰ Ä‘á»c message má»›i tá»« thá»i Ä‘iá»ƒm hiá»‡n táº¡i
    # Náº¿u muá»‘n Ä‘á»c tá»« Ä‘áº§u, dÃ¹ng "earliest"
    print("âœ“ ÄÃ£ káº¿t ná»‘i thÃ nh cÃ´ng tá»›i Kafka topic 'user-events'\n")
    
    # BÆ°á»›c 3: Äá»‹nh nghÄ©a Schema cho dá»¯ liá»‡u JSON
    # Schema giÃºp Spark hiá»ƒu cáº¥u trÃºc dá»¯ liá»‡u trong message
    # Má»—i message tá»« topic user-events cÃ³ cáº¥u trÃºc: user_id, movie_id, event_type, timestamp
    print("=" * 60)
    print("BÆ°á»›c 3: Äá»‹nh nghÄ©a Schema cho dá»¯ liá»‡u JSON")
    print("=" * 60)
    
    user_events_schema = StructType([
        StructField("user_id", IntegerType(), True),      # ID ngÆ°á»i dÃ¹ng
        StructField("movie_id", IntegerType(), True),     # ID phim
        StructField("event_type", StringType(), True),    # Loáº¡i sá»± kiá»‡n (click, watch, etc.)
        StructField("timestamp", LongType(), True),       # Thá»i gian sá»± kiá»‡n (Unix timestamp)
    ])
    
    print("âœ“ Schema Ä‘Ã£ Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a:")
    print("  - user_id: IntegerType")
    print("  - movie_id: IntegerType")
    print("  - event_type: StringType")
    print("  - timestamp: LongType\n")
    
    # BÆ°á»›c 4: Parse dá»¯ liá»‡u JSON tá»« Kafka message
    # Kafka message cÃ³ format: key, value, topic, partition, offset, timestamp
    # ChÃºng ta quan tÃ¢m Ä‘áº¿n 'value' - nÆ¡i chá»©a dá»¯ liá»‡u JSON
    print("=" * 60)
    print("BÆ°á»›c 4: Parse dá»¯ liá»‡u JSON tá»« Kafka message")
    print("=" * 60)
    
    # Chuyá»ƒn Ä‘á»•i value tá»« binary sang string
    # Sau Ä‘Ã³ parse JSON theo schema Ä‘Ã£ Ä‘á»‹nh nghÄ©a
    parsed_events_df = kafka_stream_df \
        .selectExpr("CAST(value AS STRING)") \
        .withColumn("data", from_json(col("value"), user_events_schema)) \
        .select("data.*")
    
    print("âœ“ Dá»¯ liá»‡u JSON Ä‘Ã£ Ä‘Æ°á»£c parse thÃ nh cÃ´ng\n")
    
    # BÆ°á»›c 5: Chuyá»ƒn Ä‘á»•i vÃ  lÃ m sáº¡ch dá»¯ liá»‡u
    # Chuyá»ƒn timestamp tá»« Unix timestamp (Long) sang TimestampType
    # ThÃªm cá»™t processed_at Ä‘á»ƒ biáº¿t thá»i Ä‘iá»ƒm xá»­ lÃ½
    print("=" * 60)
    print("BÆ°á»›c 5: Chuyá»ƒn Ä‘á»•i vÃ  lÃ m sáº¡ch dá»¯ liá»‡u")
    print("=" * 60)
    
    transformed_events_df = parsed_events_df \
        .withColumn("event_timestamp", (col("timestamp") / 1000).cast(TimestampType())) \
        .withColumn("processed_at", current_timestamp()) \
        .select(
            "user_id",
            "movie_id", 
            "event_type",
            "event_timestamp",
            "processed_at"
        )
    
    print("âœ“ Dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c chuyá»ƒn Ä‘á»•i:")
    print("  - timestamp (ms) -> event_timestamp (TimestampType)")
    print("  - ThÃªm cá»™t processed_at (thá»i Ä‘iá»ƒm xá»­ lÃ½)\n")
    
    # BÆ°á»›c 6: Äá»‹nh nghÄ©a hÃ m ghi dá»¯ liá»‡u vÃ o PostgreSQL
    # foreachBatch cho phÃ©p xá»­ lÃ½ tá»«ng batch dá»¯ liá»‡u
    # Má»—i khi cÃ³ message má»›i, hÃ m nÃ y sáº½ Ä‘Æ°á»£c gá»i
    print("=" * 60)
    print("BÆ°á»›c 6: Chuáº©n bá»‹ ghi dá»¯ liá»‡u vÃ o PostgreSQL")
    print("=" * 60)
    print(f"Database URL: {DB_URL}")
    print(f"Target Table: user_events\n")
    
    def write_user_events_to_postgres(batch_df, epoch_id):
        """
        HÃ m nÃ y Ä‘Æ°á»£c gá»i cho má»—i micro-batch cá»§a streaming data
        
        Parameters:
        - batch_df: DataFrame chá»©a dá»¯ liá»‡u cá»§a batch hiá»‡n táº¡i
        - epoch_id: ID cá»§a batch (tÄƒng dáº§n theo thá»i gian)
        """
        
        # Kiá»ƒm tra xem batch cÃ³ dá»¯ liá»‡u khÃ´ng
        record_count = batch_df.count()
        
        if record_count > 0:
            print(f"\n{'='*60}")
            print(f"Epoch {epoch_id}: Äang xá»­ lÃ½ {record_count} records má»›i")
            print(f"{'='*60}")
            
            # Hiá»ƒn thá»‹ má»™t vÃ i record máº«u Ä‘á»ƒ debug
            print("Sample data:")
            batch_df.show(5, truncate=False)
            
            # Ghi dá»¯ liá»‡u vÃ o PostgreSQL
            # mode("append"): ThÃªm dá»¯ liá»‡u má»›i vÃ o báº£ng, khÃ´ng ghi Ä‘Ã¨
            batch_df.write \
                .format("jdbc") \
                .option("url", DB_URL) \
                .option("dbtable", "user_events") \
                .option("user", DB_USER) \
                .option("password", DB_PASSWORD) \
                .option("driver", "org.postgresql.Driver") \
                .mode("append") \
                .save()
            
            print(f"âœ“ ÄÃ£ ghi thÃ nh cÃ´ng {record_count} records vÃ o báº£ng user_events")
            print(f"{'='*60}\n")
        else:
            print(f"Epoch {epoch_id}: KhÃ´ng cÃ³ dá»¯ liá»‡u má»›i trong batch nÃ y")
    
    # BÆ°á»›c 7: Báº¯t Ä‘áº§u streaming query
    # writeStream: Báº¯t Ä‘áº§u ghi streaming data
    # outputMode("append"): Chá»‰ ghi cÃ¡c row má»›i
    # foreachBatch: Xá»­ lÃ½ tá»«ng batch báº±ng hÃ m Ä‘Ã£ Ä‘á»‹nh nghÄ©a
    print("=" * 60)
    print("BÆ°á»›c 7: Báº¯t Ä‘áº§u Streaming Query")
    print("=" * 60)
    print("Streaming Ä‘ang cháº¡y vÃ  Ä‘á»£i message má»›i tá»« topic 'user-events'...")
    print("Nháº¥n Ctrl+C Ä‘á»ƒ dá»«ng\n")
    
    query = transformed_events_df \
        .writeStream \
        .outputMode("append") \
        .foreachBatch(write_user_events_to_postgres) \
        .option("checkpointLocation", "/tmp/checkpoint/user-events") \
        .start()
    
    # checkpointLocation: LÆ°u tráº¡ng thÃ¡i xá»­ lÃ½ Ä‘á»ƒ cÃ³ thá»ƒ recovery khi bá»‹ lá»—i
    # Spark sáº½ nhá»› message nÃ o Ä‘Ã£ Ä‘Æ°á»£c xá»­ lÃ½
    
    print("âœ“ Streaming Query Ä‘Ã£ Ä‘Æ°á»£c khá»Ÿi Ä‘á»™ng thÃ nh cÃ´ng!")
    print("âœ“ Há»‡ thá»‘ng Ä‘ang láº¯ng nghe vÃ  xá»­ lÃ½ message real-time...\n")
    
    # BÆ°á»›c 8: Chá» Ä‘á»£i vÃ  xá»­ lÃ½ liÃªn tá»¥c
    # awaitTermination(): Giá»¯ cho chÆ°Æ¡ng trÃ¬nh cháº¡y mÃ£i mÃ£i
    # Chá»‰ dá»«ng khi cÃ³ lá»—i hoáº·c ngÆ°á»i dÃ¹ng dá»«ng thá»§ cÃ´ng (Ctrl+C)
    print("=" * 60)
    print("BÆ°á»›c 8: Cháº¡y liÃªn tá»¥c vÃ  Ä‘á»£i message má»›i")
    print("=" * 60)
    print("Há»‡ thá»‘ng Ä‘ang hoáº¡t Ä‘á»™ng 24/7...")
    print("Má»—i khi cÃ³ message má»›i trong topic 'user-events',")
    print("dá»¯ liá»‡u sáº½ tá»± Ä‘á»™ng Ä‘Æ°á»£c lÆ°u vÃ o database.\n")
    
    try:
        query.awaitTermination()
    except KeyboardInterrupt:
        print("\n\n" + "=" * 60)
        print("ÄÃ£ nháº­n tÃ­n hiá»‡u dá»«ng tá»« ngÆ°á»i dÃ¹ng")
        print("Äang dá»«ng Streaming Query...")
        print("=" * 60)
        query.stop()
        print("âœ“ Streaming Query Ä‘Ã£ dá»«ng thÃ nh cÃ´ng")
    except Exception as e:
        print(f"\n\nâŒ Lá»—i xáº£y ra: {str(e)}")
        query.stop()
        raise


# --- HÃ m Main (Ratings Processor) ---
def main():
    """
    HÃ m main - xá»­ lÃ½ ratings tá»« Kafka topic Ä‘Æ°á»£c cáº¥u hÃ¬nh
    
    HÃ m nÃ y subscribe topic tá»« biáº¿n mÃ´i trÆ°á»ng KAFKA_TOPIC,
    filter láº¥y events cÃ³ event_type="click" hoáº·c "watch",
    vÃ  lÆ°u vÃ o báº£ng ratings vá»›i rating: click=4.0, watch=5.0
    """
    
    # BÆ°á»›c 1: Khá»Ÿi táº¡o Spark Session
    # SparkSession lÃ  Ä‘iá»ƒm vÃ o chÃ­nh Ä‘á»ƒ lÃ m viá»‡c vá»›i Spark
    # AppName giÃºp nháº­n diá»‡n á»©ng dá»¥ng trong Spark UI
    print("=" * 60)
    print("BÆ°á»›c 1: Khá»Ÿi táº¡o Spark Session cho Ratings Processing")
    print("=" * 60)
    
    spark = SparkSession \
        .builder \
        .appName("RatingsProcessor") \
        .getOrCreate()
    
    # Giáº£m má»©c Ä‘á»™ log Ä‘á»ƒ dá»… theo dÃµi, chá»‰ hiá»ƒn thá»‹ WARNING trá»Ÿ lÃªn
    spark.sparkContext.setLogLevel("WARN")
    print("âœ“ Spark Session Ä‘Ã£ Ä‘Æ°á»£c khá»Ÿi táº¡o thÃ nh cÃ´ng\n")
    
    # BÆ°á»›c 2: Káº¿t ná»‘i vÃ  Ä‘á»c stream tá»« Kafka topic
    # readStream: Táº¡o má»™t DataFrame streaming (dá»¯ liá»‡u liÃªn tá»¥c)
    # format("kafka"): Chá»‰ Ä‘á»‹nh nguá»“n dá»¯ liá»‡u lÃ  Kafka
    print("=" * 60)
    print("BÆ°á»›c 2: Káº¿t ná»‘i tá»›i Kafka vÃ  subscribe topic")
    print("=" * 60)
    print(f"Kafka Broker: {KAFKA_BROKER}")
    print(f"Topic: {KAFKA_TOPIC}")
    
    kafka_stream_df = spark \
        .readStream \
        .format("kafka") \
        .option("kafka.bootstrap.servers", KAFKA_BROKER) \
        .option("subscribe", KAFKA_TOPIC) \
        .option("startingOffsets", "latest") \
        .load()
    
    # startingOffsets="latest": Chá»‰ Ä‘á»c message má»›i tá»« thá»i Ä‘iá»ƒm hiá»‡n táº¡i
    # Náº¿u muá»‘n Ä‘á»c tá»« Ä‘áº§u, dÃ¹ng "earliest"
    print(f"âœ“ ÄÃ£ káº¿t ná»‘i thÃ nh cÃ´ng tá»›i Kafka topic '{KAFKA_TOPIC}'\n")
    
    # BÆ°á»›c 3: Äá»‹nh nghÄ©a Schema cho dá»¯ liá»‡u JSON
    # Schema giÃºp Spark hiá»ƒu cáº¥u trÃºc dá»¯ liá»‡u trong message
    # Má»—i message cÃ³ cáº¥u trÃºc: user_id, movie_id, event_type, timestamp
    print("=" * 60)
    print("BÆ°á»›c 3: Äá»‹nh nghÄ©a Schema cho dá»¯ liá»‡u JSON")
    print("=" * 60)
    
    ratings_schema = StructType([
        StructField("user_id", IntegerType(), True),      # ID ngÆ°á»i dÃ¹ng
        StructField("movie_id", IntegerType(), True),     # ID phim
        StructField("event_type", StringType(), True),    # Loáº¡i sá»± kiá»‡n (click, watch, etc.)
        StructField("timestamp", LongType(), True),       # Thá»i gian sá»± kiá»‡n (Unix timestamp milliseconds)
    ])
    
    print("âœ“ Schema Ä‘Ã£ Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a:")
    print("  - user_id: IntegerType")
    print("  - movie_id: IntegerType")
    print("  - event_type: StringType")
    print("  - timestamp: LongType (milliseconds)\n")
    
    # BÆ°á»›c 4: Parse dá»¯ liá»‡u JSON tá»« Kafka message
    # Kafka message cÃ³ format: key, value, topic, partition, offset, timestamp
    # ChÃºng ta quan tÃ¢m Ä‘áº¿n 'value' - nÆ¡i chá»©a dá»¯ liá»‡u JSON
    print("=" * 60)
    print("BÆ°á»›c 4: Parse dá»¯ liá»‡u JSON tá»« Kafka message")
    print("=" * 60)
    
    # Chuyá»ƒn Ä‘á»•i value tá»« binary sang string
    # Sau Ä‘Ã³ parse JSON theo schema Ä‘Ã£ Ä‘á»‹nh nghÄ©a
    parsed_events_df = kafka_stream_df \
        .selectExpr("CAST(value AS STRING)") \
        .withColumn("data", from_json(col("value"), ratings_schema)) \
        .select("data.*")
    
    print("âœ“ Dá»¯ liá»‡u JSON Ä‘Ã£ Ä‘Æ°á»£c parse thÃ nh cÃ´ng\n")
    
    # BÆ°á»›c 5: Chuyá»ƒn Ä‘á»•i vÃ  lÃ m sáº¡ch dá»¯ liá»‡u
    # Filter chá»‰ láº¥y events cÃ³ event_type = "click" hoáº·c "watch"
    # Chuyá»ƒn Ä‘á»•i thÃ nh rating: click = 4.0, watch = 5.0
    # Convert timestamp tá»« Unix timestamp (milliseconds) sang TimestampType
    # Chia cho 1000 Ä‘á»ƒ chuyá»ƒn tá»« milliseconds sang seconds
    print("=" * 60)
    print("BÆ°á»›c 5: Filter vÃ  chuyá»ƒn Ä‘á»•i dá»¯ liá»‡u")
    print("=" * 60)
    print("Filter: Chá»‰ láº¥y event_type = 'click' hoáº·c 'watch'")
    print("Rating: click = 4.0, watch = 5.0")
    print("Timestamp: milliseconds -> TimestampType (seconds)")
    
    transformed_ratings_df = parsed_events_df \
        .filter((col("event_type") == "click") | (col("event_type") == "watch")) \
        .withColumn("rating", when(col("event_type") == "click", lit(4.0))
                           .when(col("event_type") == "watch", lit(5.0))) \
        .withColumn("timestamp", (col("timestamp") / 1000).cast(TimestampType())) \
        .select(
            "user_id",
            "movie_id",
            "rating",
            "timestamp"
        )
    
    print("âœ“ Dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c filter vÃ  chuyá»ƒn Ä‘á»•i:")
    print("  - Filter: event_type == 'click' OR event_type == 'watch'")
    print("  - rating: click = 4.0, watch = 5.0")
    print("  - timestamp: milliseconds / 1000 -> TimestampType\n")
    
    # BÆ°á»›c 6: Äá»‹nh nghÄ©a hÃ m ghi dá»¯ liá»‡u vÃ o PostgreSQL
    # foreachBatch cho phÃ©p xá»­ lÃ½ tá»«ng batch dá»¯ liá»‡u
    # Má»—i khi cÃ³ message má»›i, hÃ m nÃ y sáº½ Ä‘Æ°á»£c gá»i
    print("=" * 60)
    print("BÆ°á»›c 6: Chuáº©n bá»‹ ghi dá»¯ liá»‡u vÃ o PostgreSQL")
    print("=" * 60)
    print(f"Database URL: {DB_URL}")
    print(f"Target Table: {DB_TABLE}\n")
    
    def write_ratings_to_postgres(batch_df, epoch_id):
        """
        HÃ m nÃ y Ä‘Æ°á»£c gá»i cho má»—i micro-batch cá»§a streaming data
        
        Parameters:
        - batch_df: DataFrame chá»©a dá»¯ liá»‡u cá»§a batch hiá»‡n táº¡i
        - epoch_id: ID cá»§a batch (tÄƒng dáº§n theo thá»i gian)
        """
        
        # Kiá»ƒm tra xem batch cÃ³ dá»¯ liá»‡u khÃ´ng
        record_count = batch_df.count()
        
        if record_count > 0:
            print(f"\n{'='*60}")
            print(f"Epoch {epoch_id}: Äang xá»­ lÃ½ {record_count} ratings má»›i")
            print(f"{'='*60}")
            
            # Hiá»ƒn thá»‹ má»™t vÃ i record máº«u Ä‘á»ƒ debug (trÆ°á»›c khi convert)
            print("Sample data (before conversion):")
            batch_df.show(5, truncate=False)
            
            # Chuyá»ƒn Ä‘á»•i timestamp tá»« TimestampType vá» Unix timestamp (integer)
            # unix_timestamp() tráº£ vá» seconds, nhÃ¢n 1000 Ä‘á»ƒ cÃ³ milliseconds
            batch_df_converted = batch_df \
                .withColumn("timestamp", (unix_timestamp(col("timestamp")) * 1000).cast("long"))
            
            print("Sample data (after conversion to Unix timestamp):")
            batch_df_converted.show(5, truncate=False)
            
            # Ghi dá»¯ liá»‡u vÃ o PostgreSQL
            # mode("append"): ThÃªm dá»¯ liá»‡u má»›i vÃ o báº£ng, khÃ´ng ghi Ä‘Ã¨
            batch_df_converted.write \
                .format("jdbc") \
                .option("url", DB_URL) \
                .option("dbtable", DB_TABLE) \
                .option("user", DB_USER) \
                .option("password", DB_PASSWORD) \
                .option("driver", "org.postgresql.Driver") \
                .mode("append") \
                .save()
            
            print(f"âœ“ ÄÃ£ ghi thÃ nh cÃ´ng {record_count} ratings vÃ o báº£ng {DB_TABLE}")
            print(f"{'='*60}\n")
        else:
            print(f"Epoch {epoch_id}: KhÃ´ng cÃ³ dá»¯ liá»‡u má»›i trong batch nÃ y")
    
    # BÆ°á»›c 7: Báº¯t Ä‘áº§u streaming query
    # writeStream: Báº¯t Ä‘áº§u ghi streaming data
    # outputMode("update"): Ghi cÃ¡c row Ä‘Ã£ update
    # foreachBatch: Xá»­ lÃ½ tá»«ng batch báº±ng hÃ m Ä‘Ã£ Ä‘á»‹nh nghÄ©a
    print("=" * 60)
    print("BÆ°á»›c 7: Báº¯t Ä‘áº§u Streaming Query")
    print("=" * 60)
    print(f"Streaming Ä‘ang cháº¡y vÃ  Ä‘á»£i message má»›i tá»« topic '{KAFKA_TOPIC}'...")
    print("Nháº¥n Ctrl+C Ä‘á»ƒ dá»«ng\n")
    
    query = transformed_ratings_df \
        .writeStream \
        .outputMode("update") \
        .foreachBatch(write_ratings_to_postgres) \
        .option("checkpointLocation", "/tmp/checkpoint/ratings") \
        .start()
    
    # checkpointLocation: LÆ°u tráº¡ng thÃ¡i xá»­ lÃ½ Ä‘á»ƒ cÃ³ thá»ƒ recovery khi bá»‹ lá»—i
    # Spark sáº½ nhá»› message nÃ o Ä‘Ã£ Ä‘Æ°á»£c xá»­ lÃ½
    
    print("âœ“ Streaming Query Ä‘Ã£ Ä‘Æ°á»£c khá»Ÿi Ä‘á»™ng thÃ nh cÃ´ng!")
    print("âœ“ Há»‡ thá»‘ng Ä‘ang láº¯ng nghe vÃ  xá»­ lÃ½ message real-time...\n")
    
    # BÆ°á»›c 8: Chá» Ä‘á»£i vÃ  xá»­ lÃ½ liÃªn tá»¥c
    # awaitTermination(): Giá»¯ cho chÆ°Æ¡ng trÃ¬nh cháº¡y mÃ£i mÃ£i
    # Chá»‰ dá»«ng khi cÃ³ lá»—i hoáº·c ngÆ°á»i dÃ¹ng dá»«ng thá»§ cÃ´ng (Ctrl+C)
    print("=" * 60)
    print("BÆ°á»›c 8: Cháº¡y liÃªn tá»¥c vÃ  Ä‘á»£i message má»›i")
    print("=" * 60)
    print("Há»‡ thá»‘ng Ä‘ang hoáº¡t Ä‘á»™ng 24/7...")
    print(f"Má»—i khi cÃ³ message 'click' hoáº·c 'watch' trong topic '{KAFKA_TOPIC}',")
    print("dá»¯ liá»‡u sáº½ tá»± Ä‘á»™ng Ä‘Æ°á»£c lÆ°u vÃ o database.\n")
    
    try:
        query.awaitTermination()
    except KeyboardInterrupt:
        print("\n\n" + "=" * 60)
        print("ÄÃ£ nháº­n tÃ­n hiá»‡u dá»«ng tá»« ngÆ°á»i dÃ¹ng")
        print("Äang dá»«ng Streaming Query...")
        print("=" * 60)
        query.stop()
        print("âœ“ Streaming Query Ä‘Ã£ dá»«ng thÃ nh cÃ´ng")
    except Exception as e:
        print(f"\n\nâŒ Lá»—i xáº£y ra: {str(e)}")
        query.stop()
        raise


if __name__ == "__main__":
    # Kiá»ƒm tra biáº¿n mÃ´i trÆ°á»ng Ä‘á»ƒ quyáº¿t Ä‘á»‹nh cháº¡y hÃ m nÃ o
    # RUN_MODE cÃ³ thá»ƒ lÃ : "user_events" hoáº·c "ratings" (default)
    run_mode = os.environ.get('RUN_MODE', 'ratings')
    
    if run_mode == 'user_events':
        print("ğŸš€ Starting User Events Subscriber...")
        print("=" * 60)
        subscribe_user_events()
    else:
        print("ğŸš€ Starting Ratings Processor (Main)...") 
        print("=" * 60)
        main()